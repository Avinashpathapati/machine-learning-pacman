1.

params = {
    # Model backups
    'load_file': None,
    'save_file': None,
    'save_interval' : 10000, 

    # Training parameters
    'train_start': 15000,    # Episodes before training starts
    'batch_size': 32,       # Replay memory batch size
    'mem_size': 100000,     # Replay memory size

    'discount': 0.99,       # Discount rate (gamma value)
    'lr': .00025,            # Learning reate
    
    # Epsilon value (epsilon-greedy)
    'eps': 1.0,             # Epsilon start value
    'eps_final': 0.1,       # Epsilon end value
    'eps_step': 50000       # Epsilon steps between start and end (linear)
}                     

Games:10000 Training: 9000 Layout: smallGrid

# 10000 | steps: 176015 | steps_t: 152290 | t: 15948.916353 | r:    96.000000 | e:   0.100000 | Q:  98.507744 | won: True 
('Average Score:', 431.623)
('Scores:       ', '503.0, 495.0, 503.0, 505.0, 503.0, 503.0, 505.0, -514.0, 503.0, 503.0, 503.0, 505.0, 495.0, -512.0, 499.0, 505.0, 505.0, -512.0, 499.0, 499.0, -528.0, 503.0, 503.0, -503.0, 505.0, 505.0, 501.0, 505.0, -511.0, 499.0, 505.0, 503.0, 503.0, 503.0, 503.0, 501.0, 503.0, 503.0, 505.0, -507.0, 503.0, 503.0, 503.0, 503.0, 503.0, 491.0, 491.0, 503.0, 499.0, 505.0, 495.0, 505.0, 497.0, 505.0, 495.0, 505.0, 503.0, 507.0, 503.0, -512.0, 503.0, -504.0, 495.0, 505.0, 495.0, 505.0, 505.0, 505.0, 503.0, -507.0, 503.0, 503.0, 505.0, 505.0, 503.0, 501.0, 505.0, 505.0, -508.0, 495.0, 505.0, 503.0, 505.0, 487.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 479.0, 495.0, 503.0, 495.0, 505.0, 489.0, 503.0, 505.0, 503.0, 507.0, 505.0, 495.0, -506.0, 503.0, -511.0, 495.0, 503.0, 505.0, 503.0, 495.0, 499.0, 505.0, 505.0, 503.0, -512.0, 503.0, 503.0, 505.0, 503.0, 503.0, 505.0, -506.0, 491.0, 505.0, 505.0, 505.0, 495.0, 507.0, 497.0, 505.0, 505.0, 499.0, 503.0, 505.0, 495.0, 503.0, 505.0, 505.0, 503.0, 505.0, 503.0, 505.0, 505.0, 503.0, 503.0, 501.0, 503.0, 503.0, 503.0, 495.0, 503.0, 503.0, 495.0, 503.0, 505.0, -510.0, 503.0, 505.0, 505.0, -504.0, 507.0, 501.0, 505.0, 505.0, 505.0, 503.0, -512.0, 503.0, 499.0, 505.0, 499.0, 505.0, 505.0, 505.0, 503.0, 507.0, 503.0, 503.0, 505.0, 505.0, 507.0, 507.0, 503.0, -511.0, 501.0, 505.0, 501.0, 499.0, 505.0, 501.0, 503.0, 495.0, 505.0, 495.0, -504.0, 495.0, 501.0, 507.0, -525.0, 501.0, 503.0, 503.0, 499.0, 499.0, 499.0, 499.0, 503.0, 505.0, 503.0, 501.0, 499.0, 503.0, 503.0, 495.0, 503.0, 505.0, 505.0, 505.0, 503.0, 499.0, 501.0, 503.0, 505.0, 505.0, 503.0, 505.0, 505.0, 499.0, 503.0, -512.0, 505.0, 501.0, 497.0, 495.0, 503.0, 505.0, 503.0, -507.0, 505.0, 505.0, 505.0, 501.0, 507.0, 505.0, 505.0, 505.0, 499.0, 499.0, 503.0, 501.0, 505.0, 505.0, 505.0, 503.0, -504.0, 507.0, 505.0, 503.0, 503.0, 501.0, 501.0, 503.0, 499.0, 495.0, 505.0, 497.0, 505.0, -507.0, 491.0, 505.0, 505.0, -510.0, 505.0, 505.0, 503.0, 507.0, 503.0, 499.0, -504.0, 499.0, 505.0, 503.0, 501.0, 505.0, 505.0, 505.0, 495.0, 505.0, 503.0, 505.0, -510.0, 501.0, 505.0, 503.0, 505.0, 499.0, 505.0, 503.0, 501.0, 507.0, 507.0, 505.0, 499.0, 505.0, 499.0, 503.0, 503.0, 505.0, 505.0, 505.0, 495.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 495.0, 505.0, 499.0, 493.0, 505.0, 503.0, 505.0, 505.0, 495.0, -505.0, 505.0, 505.0, 503.0, 495.0, 495.0, 505.0, 503.0, 501.0, 505.0, -503.0, 503.0, 499.0, 503.0, 501.0, 505.0, 505.0, 505.0, 505.0, 503.0, 505.0, 499.0, 503.0, 505.0, 495.0, 505.0, 505.0, 503.0, 501.0, 505.0, 501.0, -504.0, 505.0, 495.0, 503.0, 503.0, 503.0, 499.0, 503.0, 499.0, -507.0, 503.0, 503.0, 499.0, 503.0, 505.0, 505.0, 503.0, -504.0, 503.0, -506.0, 501.0, 505.0, 505.0, 507.0, 503.0, 503.0, 503.0, 495.0, 495.0, 503.0, -514.0, 497.0, 503.0, 499.0, 499.0, 501.0, 503.0, 503.0, 495.0, 503.0, 503.0, 503.0, 505.0, -518.0, 507.0, 505.0, 501.0, 505.0, 505.0, 501.0, 505.0, 505.0, -502.0, 501.0, 505.0, 505.0, 503.0, 503.0, 505.0, 503.0, 499.0, 501.0, 487.0, 503.0, 495.0, 505.0, 505.0, 505.0, 505.0, 503.0, -502.0, 505.0, 503.0, 505.0, 495.0, 507.0, 505.0, 505.0, 501.0, -504.0, 503.0, 503.0, 505.0, 499.0, 505.0, 499.0, 497.0, 505.0, 499.0, 505.0, 505.0, 505.0, 505.0, 505.0, 503.0, 503.0, 505.0, 505.0, 505.0, 507.0, 495.0, 505.0, 503.0, 507.0, 507.0, -505.0, 505.0, 499.0, 501.0, 503.0, 505.0, 505.0, 505.0, 503.0, 505.0, 503.0, 491.0, 505.0, 505.0, 507.0, 505.0, 505.0, 503.0, 505.0, 505.0, -504.0, 503.0, 503.0, 505.0, 503.0, 503.0, 501.0, 503.0, 503.0, 505.0, 499.0, 503.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 503.0, 507.0, 505.0, 503.0, 505.0, 505.0, 501.0, 507.0, 493.0, 501.0, 505.0, 505.0, 503.0, 487.0, 497.0, 487.0, 505.0, 505.0, 503.0, 503.0, 505.0, 503.0, 505.0, -506.0, 505.0, 505.0, 503.0, 503.0, 505.0, 505.0, 505.0, 497.0, 495.0, 485.0, 503.0, 503.0, -503.0, -504.0, 505.0, 505.0, 505.0, 503.0, 501.0, 505.0, 503.0, 503.0, 503.0, 505.0, 503.0, 505.0, -503.0, 503.0, 505.0, 505.0, 487.0, 505.0, 503.0, 505.0, 505.0, 505.0, -504.0, 503.0, 503.0, 503.0, 505.0, 505.0, 505.0, 505.0, 503.0, 503.0, 495.0, 499.0, 495.0, 505.0, 503.0, 495.0, -503.0, 503.0, 495.0, 503.0, 501.0, 505.0, 499.0, 497.0, 507.0, 493.0, 503.0, 499.0, 497.0, -502.0, -505.0, -511.0, 503.0, 495.0, 503.0, 503.0, 495.0, 507.0, 503.0, 503.0, 503.0, 503.0, 503.0, 503.0, 505.0, 503.0, 503.0, 501.0, 491.0, 503.0, 505.0, 503.0, 505.0, 507.0, 503.0, 505.0, 505.0, 499.0, 497.0, 505.0, 505.0, 505.0, 503.0, 505.0, 499.0, 503.0, 501.0, 493.0, 503.0, 505.0, 503.0, 503.0, 505.0, 505.0, 507.0, 505.0, 507.0, 499.0, 503.0, 507.0, 505.0, 499.0, 505.0, 505.0, 501.0, 493.0, -503.0, 505.0, 505.0, 507.0, 503.0, 507.0, 503.0, -504.0, 503.0, 503.0, 501.0, 505.0, 505.0, 505.0, 503.0, 501.0, 507.0, 499.0, 505.0, 493.0, 503.0, 503.0, -504.0, 507.0, 503.0, 507.0, 495.0, 499.0, 505.0, 503.0, 503.0, 503.0, 503.0, 505.0, 507.0, 503.0, 499.0, 501.0, 503.0, 503.0, 503.0, 499.0, 503.0, 503.0, 503.0, 505.0, 503.0, 503.0, 503.0, 503.0, 505.0, 505.0, 503.0, 493.0, 503.0, 503.0, 503.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 499.0, 505.0, 503.0, 505.0, 505.0, 505.0, 505.0, 505.0, 495.0, 503.0, 505.0, 507.0, 507.0, 495.0, 503.0, 501.0, 501.0, 505.0, 495.0, 503.0, 503.0, 505.0, -504.0, 503.0, 505.0, 505.0, 495.0, 505.0, 481.0, -504.0, 503.0, 507.0, 505.0, 501.0, 505.0, 505.0, 505.0, -507.0, 505.0, 501.0, 503.0, 503.0, 505.0, 505.0, 503.0, 505.0, -514.0, 501.0, 503.0, 507.0, 507.0, -510.0, -506.0, 505.0, 503.0, 505.0, 505.0, 503.0, 495.0, 505.0, 503.0, 505.0, 503.0, 497.0, 497.0, 505.0, 505.0, 499.0, 507.0, 503.0, 501.0, 495.0, 495.0, 503.0, 503.0, 503.0, -507.0, 503.0, 505.0, 499.0, 497.0, 503.0, 503.0, 505.0, 503.0, 505.0, 503.0, 507.0, 503.0, 505.0, 503.0, 495.0, 505.0, -507.0, 499.0, 495.0, 503.0, 495.0, 503.0, 505.0, 507.0, 503.0, 505.0, 505.0, 495.0, 505.0, 485.0, 495.0, 503.0, 507.0, 503.0, 503.0, 491.0, 505.0, -504.0, 495.0, 503.0, 505.0, 503.0, 489.0, 501.0, 499.0, 489.0, 503.0, 505.0, -508.0, 499.0, 487.0, 505.0, 503.0, 499.0, 507.0, 505.0, 505.0, 503.0, 501.0, 503.0, 503.0, 505.0, 507.0, 505.0, 503.0, 503.0, 499.0, 503.0, 495.0, 495.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 505.0, 501.0, 505.0, 505.0, 505.0, 505.0, 499.0, 505.0, 503.0, 495.0, 505.0, 505.0, 507.0, 495.0, 503.0, 487.0, -511.0, 491.0, 503.0, 505.0, 503.0, -504.0, 499.0, 501.0, 495.0, 495.0, 503.0, 495.0, 505.0, 495.0, 505.0, 495.0, 505.0, 503.0, 493.0, 499.0, 503.0, 491.0, 505.0, 499.0, 503.0, 503.0, 491.0, 503.0, 495.0, 503.0, 495.0, 505.0, 499.0, 505.0, 503.0, 493.0, 501.0, -510.0, 505.0, 503.0, 499.0, 495.0, 505.0, 505.0, 507.0, 505.0, 503.0, 503.0, 505.0, 503.0, 503.0, 503.0, 503.0, 495.0, -503.0, 503.0, 503.0, 499.0, 503.0, 505.0, -504.0, 505.0, 503.0, 503.0, 505.0, 505.0, 505.0, 503.0, 499.0, 505.0, 495.0, 505.0, 505.0, 503.0, 505.0, 505.0, 503.0, 505.0, 495.0, 505.0, 505.0, 505.0, 505.0, -504.0, 503.0, 505.0, 503.0, 499.0, 503.0, 501.0, 505.0, -513.0, 501.0, 503.0, 505.0, 505.0, 503.0, 497.0, 501.0, 503.0, 503.0, 503.0, 503.0, 501.0, 505.0, 505.0, 505.0, 495.0, 503.0, 505.0, 505.0, 503.0, 495.0, 505.0, 503.0, 503.0, 495.0, 505.0, 505.0, 503.0, 505.0')
Win Rate:      930/1000 (0.93)

2.

params = {
    # Model backups
    'load_file': None,
    'save_file': '2_model',
    'save_interval' : 10000, 

    # Training parameters
    'train_start': 15000,    # Episodes before training starts
    'batch_size': 64,       # Replay memory batch size
    'mem_size': 1000000,     # Replay memory size

    'discount': 0.99,       # Discount rate (gamma value)
    'lr': .00025,            # Learning reate
    
    # Epsilon value (epsilon-greedy)
    'eps': 1.0,             # Epsilon start value
    'eps_final': 0.1,       # Epsilon end value
    'eps_step': 100000       # Epsilon steps between start and end (linear)
}

Games:20000 Training: 18000 Layout: mediumClassic